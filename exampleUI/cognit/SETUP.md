# Cognit - LangGraph Backend Setup Guide

## ğŸ‰ Implementation Complete!

Your fully functional LangGraph backend with agentic workflows has been successfully implemented!

## What's Been Created

### âœ… Backend (Node.js + Express + LangGraph)
- **6 AI Agents** with separate LangGraph workflows:
  1. **The Reality Checker** - Validation & norms (always on)
  2. **The Routine Architect** - Efficiency & logistics
  3. **The Guilt Dissolver** - Mental health support
  4. **Sleep Recovery** - Sleep management
  5. **Homework Helper** - Academic conflict resolution
  6. **Transition Tamer** - Transition management

- **Express Server** with:
  - RESTful API endpoints
  - Server-Sent Events (SSE) for streaming responses
  - Session management with in-memory storage
  - Gemini API integration
  - CORS configuration for frontend

### âœ… Frontend Integration
- **Updated ChatInterface** with:
  - State management for messages
  - Agent selector dropdown
  - SSE streaming client
  - Real-time message updates
  - Loading states and animations
  - Bilingual support (en/tr)

### âœ… Development Configuration
- Workspace setup for monorepo
- Vite proxy for API requests
- Concurrent dev servers (frontend + backend)

## ğŸ“‹ Prerequisites

Before you can run the application, you need to have Node.js installed:

```bash
# Check if Node.js is installed
node --version

# If not installed, install Node.js (version 18 or higher)
# Visit: https://nodejs.org/
```

## ğŸš€ Installation & Setup

### Step 1: Install Dependencies

From the project root directory:

```bash
# Install root dependencies (including concurrently)
npm install

# Install backend dependencies
cd backend
npm install
cd ..
```

### Step 2: Configure API Key

Update the Gemini API key in both locations:

**Frontend** (`.env.local`):
```env
GEMINI_API_KEY=your_actual_gemini_api_key_here
```

**Backend** (`backend/.env`):
```env
GEMINI_API_KEY=your_actual_gemini_api_key_here
PORT=3001
NODE_ENV=development
LOG_LEVEL=debug
```

ğŸ’¡ **Get your Gemini API key from**: https://ai.google.dev/

### Step 3: Start the Development Servers

**Option A: Run Both Servers Concurrently** (Recommended)
```bash
npm run dev
```

This will start:
- Frontend on `http://localhost:3000` (Vite)
- Backend on `http://localhost:3001` (Express)
- Automatic proxy from frontend to backend

**Option B: Run Servers Separately**

Terminal 1 (Frontend):
```bash
npm run dev:frontend
```

Terminal 2 (Backend):
```bash
npm run dev:backend
```

## ğŸ® Usage

1. **Open your browser** to `http://localhost:3000`

2. **Select an agent** from the dropdown in the chat header:
   - The Reality Checker
   - The Routine Architect
   - The Guilt Dissolver
   - Sleep Recovery
   - Homework Helper
   - Transition Tamer

3. **Start chatting!** Type a parenting question or concern and get AI-powered guidance

4. **Switch agents** at any time to get different perspectives

5. **Language support**: Use the language toggle (if available) to switch between English and Turkish

## ğŸ” Testing the Backend

### Health Check
```bash
curl http://localhost:3001/api/health
```

Expected response:
```json
{
  "status": "ok",
  "timestamp": "2025-12-21T...",
  "service": "cognit-backend"
}
```

### List Agents
```bash
curl http://localhost:3001/api/agents
```

### Send a Test Message
```bash
curl -X POST http://localhost:3001/api/chat/message \
  -H "Content-Type: application/json" \
  -d '{
    "sessionId": "test-123",
    "agentId": "reality-checker",
    "message": "My 6-year-old is having tantrums. Is this normal?",
    "context": {
      "childAge": 6,
      "language": "en"
    }
  }'
```

## ğŸ“ Project Structure

```
cognit/
â”œâ”€â”€ backend/                      # Backend server
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ index.ts             # Express entry point
â”‚   â”‚   â”œâ”€â”€ config/              # Configuration files
â”‚   â”‚   â”‚   â”œâ”€â”€ gemini.ts        # Gemini API client
â”‚   â”‚   â”‚   â””â”€â”€ environment.ts   # Environment config
â”‚   â”‚   â”œâ”€â”€ graphs/              # LangGraph workflows (6 agents)
â”‚   â”‚   â”‚   â”œâ”€â”€ reality-checker.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ routine-architect.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ guilt-dissolver.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ sleep-recovery.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ homework-helper.ts
â”‚   â”‚   â”‚   â””â”€â”€ transition-tamer.ts
â”‚   â”‚   â”œâ”€â”€ routes/              # API routes
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.ts          # Chat endpoints (SSE)
â”‚   â”‚   â”‚   â”œâ”€â”€ agents.ts        # Agent management
â”‚   â”‚   â”‚   â””â”€â”€ health.ts        # Health check
â”‚   â”‚   â”œâ”€â”€ memory/              # Session management
â”‚   â”‚   â””â”€â”€ middleware/          # Express middleware
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ tsconfig.json
â”œâ”€â”€ components/
â”‚   â””â”€â”€ ChatInterface.tsx        # Updated with API integration
â”œâ”€â”€ vite.config.ts               # Proxy configuration
â”œâ”€â”€ package.json                 # Workspace configuration
â””â”€â”€ .env.local                   # Frontend environment variables
```

## ğŸ› Troubleshooting

### Port Already in Use
If you get "port already in use" errors:

```bash
# Find and kill process on port 3000
lsof -ti:3000 | xargs kill -9

# Find and kill process on port 3001
lsof -ti:3001 | xargs kill -9
```

### Gemini API Errors
- Make sure your API key is valid
- Check you have API credits/quota
- Verify the key is set in both `.env.local` and `backend/.env`

### CORS Errors
- Make sure backend is running on port 3001
- Check the proxy configuration in `vite.config.ts`
- Ensure CORS middleware is properly configured

### TypeScript Errors
```bash
# Rebuild backend
cd backend
npm run build
```

## ğŸ“ Next Steps

Now that your backend is fully functional, you can:

1. **Test each agent** - Try different parenting scenarios with each agent
2. **Improve workflows** - Enhance the LangGraph workflows with more nodes and logic
3. **Add features**:
   - Action plan generation in the right sidebar
   - Conversation history persistence
   - User authentication
   - Agent recommendations based on context
4. **Deploy** - Deploy to production (Vercel for frontend, Railway/Render for backend)

## ğŸ”§ Development Scripts

```bash
# Root (workspace)
npm run dev              # Run both frontend and backend
npm run dev:frontend     # Run only frontend
npm run dev:backend      # Run only backend
npm run build            # Build both frontend and backend

# Backend
cd backend
npm run dev              # Start backend in watch mode
npm run build            # Build backend
npm run start            # Start production backend
```

## ğŸ¨ Customization

### Adding New Agents
1. Create new graph in `backend/src/graphs/your-agent.ts`
2. Add to `AGENT_GRAPHS` in `backend/src/routes/chat.ts`
3. Add to agent metadata in `backend/src/routes/agents.ts`
4. Add to frontend selector in `components/ChatInterface.tsx`

### Modifying Agent Workflows
Each agent graph is in its own file. Edit the nodes and edges to change behavior:
- `backend/src/graphs/reality-checker.ts`
- `backend/src/graphs/routine-architect.ts`
- etc.

### Changing the UI
The ChatInterface is fully customizable:
- `components/ChatInterface.tsx` - Main chat component
- Uses TailwindCSS for styling
- Supports dark mode
- Bilingual (English/Turkish)

## ğŸ“š Documentation

- **LangGraph**: https://langchain-ai.github.io/langgraphjs/
- **Gemini API**: https://ai.google.dev/
- **Express**: https://expressjs.com/
- **Vite**: https://vitejs.dev/

## ğŸ¯ Success Metrics

âœ… All 6 agents implemented
âœ… Streaming responses working
âœ… Agent selection functional
âœ… Frontend-backend communication established
âœ… Bilingual support (en/tr)
âœ… Session state management
âœ… Error handling

---

**Made with â¤ï¸ using Claude Code**
